\chapter{Online algorithms}

This part of the course deals with \emph{online algorithms}. By this we mean that the input is revealed one at a time to the algorithm, and the algorithm must make an irrevocable decision every time it is revealed a part of the input. The algorithm does not have the benefit of hindsight to go back and correct a locally optimal decision it had made earlier. 

To measure the performance of such an algorithm, we calculate its \emph{competitive ratio}. This quantity measures the value output by the online algorithm on a particular sequence of input to the value that is output by the optimal algorithm for the same sequence. This optimal algorithm could even by offline, in the sense that it can make its decisions after seeing all the input. Formally, we define the notion of competitive ratio as follows.

\begin{definition}
	[Competitive ratio]
	An online algorithm $A$ for a computational problem $\mathcal{P}$ is
        said to have a competitive ratio of $c$ if for every input sequence
        $\sigma_1, \sigma_2, \ldots, \sigma_n$, the value return by $A$, given
        by $f_A(\sigma_1, \sigma_2, \ldots, \sigma_n)$ is such that
	\begin{align*}
          f_A(\sigma_1,\sigma_2,\ldots,\sigma_n) \leq c\cdot f_{\opt}(\sigma_1,\sigma_2,\ldots,\sigma_n).
	\end{align*}
	\label{def:comp-ratio}
\end{definition}

We will start with a small warm-up problem to set the stage.

\section{Warm up: Bipartite matching}

Let us start with the problem on online bipartite matching. In this problem, we have a bipartite graph $G(L\cup R, E)$ where the vertices in the set $L$ is known beforehand. The set of vertices in $R$ is revealed one at a time. When a vertex $v \in R$ is revealed, then all the neighbors $N(v)$ of $v$ are revealed. Let us start with a deterministic algorithm. We will see that the deterministic algorithm achieves a competitive ratio of $1/2$, and that this is the best ratio achievable by any deterministic algorithm.

Consider the following greedy algorithm. When a new vertex $v$ is revealed with the edges, choose an edge arbitrarily that can be included in the current matching. We start with the the empty matching. Note that this algorithm is the greedy algorithm to construct a maximal matching.

\begin{theorem}
	The greedy algorithm for maximal matching is $2$-competitive.
	\label{thm:maximal}
\end{theorem}
\begin{proof}
	If $M$ is a maximal matching and $M^\star$ is a maximum matching, we will see that $|M^\star| \leq 2|M|$. This follows from the following two observations.
	\begin{enumerate}
		\item For every edge $(u,v) \in M^\star - M$, one of the edges incident on $v$ or $u$ must be in the maximal matching, since otherwise $M$ cannot be maximal.
		\item For every edge $(u,v) \in M - M^\star$, at most $2$ edges incident on $u$ and $v$ can be in the maximum matching $M^\star$.
	\end{enumerate}
	Both the observations together imply that $|M^\star| \leq 2|M|$.
\end{proof}

We can also see that this is the best ratio achievable by any deterministic online algorithm for bipartite matching. To see this, consider the graph where $L$ consists of two vertices $u_1, u_2$. Now the first vertex $v_1$ in $R$ that comes is connected to both $u_1$ and $u_2$. No matter which edge the deterministic algorithm chooses in the matching, say $(u_1, v_1)$, the next vertex $v_2$ will be connected to $u_1$. So, the graph looks as follows.

Clearly, the maximum matching is of size $2$, whereas the deterministic algorithm gives a matching of size $1$.

Online bipartite matching is a special case of a more general problem that has received a lot attention in recent years. This is the AdWords problem. Consider the way a company like Google generates the revenue through ads. Whenever a user searches a keyword, the search engine displays a bunch of ads related to the searched keywords together with the search results. If the user clicks on any of the ads, the entity that displays the ad pays Google some revenue. This is modelled as follows: There is a set of $n$ sellers that are known beforehand. Whenever a new keyword is searched, the $n$ sellers provide the bid for that item. The job of the search engine is to assign that keyword to one of the sellers whose ad will be displayed. Each keyword can be assigned to at most one seller, and the aim of the search engine is to maximize its revenue. The sellers are constrained by a budget, and hence cannot be assigned keywords such that the sum exceeds its budget. Bipartite matching is a special case, where each seller has unit budget, and make a $0-1$ bid for every keyword that appears.

We will see that if we allow randomization, then online bipartite matching has an algorithm with competitive ratio $1 - 1/e$. Furthermore, this is the best that can be achieved by any online algorithm for bipartite matching. We will see this a little later.

\section{Online paging}

Consider the problem of maintaining a cache memory of size $k$ in response to a sequence of requests. If the request corresponds to a page already present in the cache, then it can be serviced quickly and is known as a \emph{hit}. If the request is not present in the cache, then the page has to be brought in from say the main memory, which is a slow memory, into the cache. This is known as a \emph{cache miss} or a \emph{fault}. At every cache fault, we must necessarily evict an item from the cache to make room for the new item. The goal is to design a scheme that chooses the best item to evict so that the number of cache faults is minimized. It is not hard to see that for any deterministic online paging algorithm, it is possible to construct a sequence of request adversarially such that the algorithm faults on every request. We will see this when we prove lower bounds on the competitive ratio of paging algorithms.

\subsection{Deterministic online paging}
First, we will start with some deterministic algorithms. A simple algorithm, that is also used a lot in practice, is the LRU (Least-Recently-Used) scheme. In this algorithm, whenever a request for a page that is not in the cache comes, we choose the page that was requested farthest in the past to evict. We will see that LRU is $k$-competitive, and that any deterministic algorithm that is $c$-competitive must have $c \geq k$. What does an optimal (possibly offline) algorithm for paging look like? This is obtained by the LFD (Longest-Future-Distance) scheme, where we choose the item that will be requested farthest in the future to be evicted in case of a cache fault. Notice that this is necessarily an offline algorithm.

\begin{theorem}
	The LRU algorithm is $k$-competitive.
	\label{thm:paging-det-ub}
\end{theorem}
\begin{proof}
	We will divide the sequence of requests $\sigma_1,\sigma_2,\ldots,\sigma_n$ into rounds where a round is a maximal set of requests that generate $k$ cache misses for the LRU algorithm. We will then show that in each round, the optimal algorithm must fault at least once. This will prove the bound on the competitiveness ratio.
	
	Consider an arbitrary round $i$. We will consider two cases.
	\begin{enumerate}
		\item Case 1: There is a page $\sigma_j$ that generated two faults in round $i$. Consider the sequence between these two faults for $\sigma_j$. The reason for the second fault is that even though $\sigma_j$ was brought into the cache, it was evicted at some later stage. Since LRU evicts a page that was requested farthest in the past, this means that there must have been at least $k-1$ different requests before $\sigma_j$ was evicted. Hence, in round $i$ there must have been at least $k+1$ different requests - one for the first $\sigma_j$ request, then the $k-1$ other requests before $\sigma_j$ was evicted, and finally the request for $\sigma_j$ that brought it back into the cache. Since the cache size is only $k$, no matter what the optimal algorithm does it must fault at least once on $k+1$ requests.
		\item Case 2: Suppose that all the $k$ faults in round $i$ were for distinct items. Now let $\sigma_i$ be the last request in round $i-1$. Notice that the page $\sigma_i$ is present in the cache for the LRU algorithm and the optimal algorithm. Suppose that $\sigma_i$ was not one of the $k$ faults in round $i$. This means that there are $k$ distinct page requests other than $\sigma_i$, and hence the optimal algorithm must fault at least once. 
		
		On the other hand, if $\sigma_i$ was one of the $k$ distinct faults. This means that on one of the requests in round $i$, $\sigma_i$ was evicted. Since LRU evicts the least recently used element, and $\sigma_i$ was the last request in round $i-1$, there must have been at least $k-1$ different requests before that. Together with the request that evicted $\sigma_i$ and the request for $\sigma_i$ that generated a miss, this means there were $k+1$ distinct requests in round $i$. Hence, the optimal algorithm must have faulted at least once.
	\end{enumerate}
\end{proof}

We will now see that this is the best achievable if we restrict ourselves to deterministic algorithm. The idea is to show that given a deterministic algorithm, we can always generate a sequence of requests that forces the algorithm to miss on every request. 

For concreteness let $A$ be a fixed deterministic online paging algorithm, and suppose we start with a cache with $k$ items. The first request will be an element that is not one of these elements. Thus, we have a set $S$ of $k+1$ elements such that every request will be an item from this set. In particular, the $i^{th}$ request will be the elements currently not in the cache according to the algorithm $A$. Thus, the algorithm has a cache miss on each of the requests. To understand the behaviour of the optimal algorithm, let us divide the request sequence into rounds where a round is a maximal sequence of requests that contain $k$ distinct requests. Note that $A$ has at least $k$ faults in a round. Let us now argue that the optimal algorithm (LFD) will miss at most once in a round. 

Since a round contains $k$ distinct requests, there is some element in $S$ that was never requested in that round. The optimal algorithm will then evict that item at the first miss in the round. This guarantees that there are no more misses in that round. Thus, we have shown the following.

\begin{theorem}
	Any $c$-competitive deterministic paging algorithm must have $c \geq k$.
	\label{thm:paging-det-lb}
\end{theorem}

\subsection{Randomized online paging}

In this part, we will see that randomized algorithms can achieve better guarantees on the competitive ratio. To study randomized algorithms, we need a suitable way to define the competitive ratio. Notice that in the case of a deterministic algorithm, the adversary who constructs the requests have complete information about the algorithm, and hence can tell clearly the request that the algorithm will make in any step.

In the case of a randomized algorithm, the algorithm has access to random coins. Now, even if the adversary knows the randomized algorithms, it might still not know the exact sequence of the pages evicted by the algorithm since that also depends on the random coins of the algorithm. This can potentially mean that we have an algorithm that has a better competitive ratio. To formalize this notion, let us define what an \emph{oblivious adversary} is.

We can think of an oblivious adversary as someone who knows the randomized algorithm, but has no access to the random coins that is used by the algorithm in its execution. Thus we can think of an oblivious adversary looking at the source code of the randomized algorithm and generating a sequence of requests. The oblivious adversary then runs the optimal (possibly offline) algorithm on this sequence. Notice that the outcome of the optimal algorithm is deterministic. But now, the outcome of the online algorithm is a random variable that depends on its internal coin tosses. Like before, we say that a randomized online algorithm has a competitive ratio of $c$ if there is a $\delta$ such that for every sequence $\sigma_1, \sigma_2, \ldots, \sigma_n$, we have
\begin{align*}
	\E(f_A(\sigma_1,\sigma_2,\ldots,\sigma_n)) \leq c. f_{\opt}(\sigma_1, \sigma_2, \ldots, \sigma_n).
\end{align*}
Here the expectation is over the internal coin tosses on the algorithm $A$. We will show that there is an online paging algorithm with a competitive ratio of $2H_k$, and that there is an almost matching lower bound. First we will describe the randomized paging algorithm.

This is known as the \marker algorithm. In this algorithm, we have a marker bit associated with each cache location. The algorithm is divided into rounds. Each round start with the marker bits all set to $0$. When a cache request comes, if the element is present in the cache, the corresponding bit is set to $1$, if it is not already so. If the request is a miss, we choose a location uniformly at random from all the positions whose bits are $0$, evict that item and put the new item in that location. The corresponding bit is set to $1$. Once all the bits are set to $1$, the round is completed when a cache request to an item not currently in the cache arrives. At this stage all the marker bits are set to $0$, and the next round starts.

\begin{theorem}
	The \marker algorithm is $2H_k$-competitive.
	\label{thm:rand-paging-ub}
\end{theorem}
\begin{proof}
	Our analysis is quite similar to what we saw earlier. We will divide the sequence of requests into rounds, then give an upper bound on the expected number of cache misses by the \marker algorithm and lower bound for the number of misses by the optimal algorithm. Here the notion of a round is what is defined by the \marker algorithm. In a particular round $i$, let $I_O$ denote the items that were requested in round $i$ and in round $i-1$, and let $I_N$ denote the items that were requested in round $i$, but not in round $i-1$. 
	
	Firstly, note that for each item in $I_N$, the \marker algorithm will fault. This is because round $i-1$ ended when the first request to an element not in cache arrived with all the marker bits set to $1$. The only way a marker bit is set to $1$ is when that particular element is requested. Once the marker bit is set to $1$, the corresponding element is never evicted in that round. 
	
	Our aim is to find the expected number of elements in $I_O$ that faults in round $i$. Consider the $j^{th}$ element in $I_O$ when it is first requested in round $i$. Now, the positions where the first $j-1$ elements of $I_O$ were occupied at the start of round $i$ have their bit set to $1$ since either one of the $j-1$ elements is already present there and was requested, or it was evicted and a new element from $I_N$ is placed there and the bit is set to $1$. So, out of the at most $|I_N| + j - 1$ distinct requests preceding the request for the $j^{th}$ item in $I_O$, $j-1$ requests have been placed in the position corresponding to the first $j-1$ elements in $I_O$. The remaining at most $|I_N|$ requests are placed in the remaining $k - j + 1$ positions, one of which is the position where item $j$ is. Therefore, the probability that there is a cache miss on item $j$ is at most $|I_N|/(k - j + 1)$. Let us call $|I_N| = n_i$, the number of new requests in round $i$. Thus, we have the probability of a cache miss on item $j$ to be $n_i/(k-j+1)$.
	
	Thus the expected number of cache misses in round $i$ of the algorithm is given by
	\begin{align*}
		n_i + \sum_{j=1}^{k-n_i} \frac{n_i}{k-j+1} &= n_i + n_i\sum_{\ell = n_i + 1}^k \frac{1}{\ell}\\
		&= n_i + n_i(H_k - H_{n_i})\\
		&\leq n_i H_k.
	\end{align*}
	The total number of misses across the entire request sequence is therefore $H_k \sum_{i=1}^p n_i$ where $p$ is the number of rounds.
	
	Now, let us look at the case of the optimal paging algorithm and the number of its cache misses. Consider a round $i$, and let $n_i$ be the new items that were requested in round $i$. Suppose that $d_i$ was the number of elements present in the cache of the offline algorithm that are not present in the cache of the \marker algorithm at the start of a round $i$. This means that the offline algorithm has at least $n_i - d_i$ cache misses in round $i$. Similarly, the offline algorithm has $d_{i+1}$ elements in the cache after round $i$ that are not in the \marker algorithm. Now, every element in the cache of the \marker algorithm was requested in round $i$. So, if there are $d_{i+1}$ elements in the offline algorithm that are not in the cache of the \marker algorithm, there must have been at least $d_{i+1}$ cache misses for the offline algorithm. So, we can say that the number of cache misses in round $i$ is at least $(n_i - d_i + d_{i+1})/2$. At the start of round $1$, both the algorithms start with the same cache content, and hence $d_1 = 0$. Thus the total number of cache misses by the offline algorithm is at least $(\sum_{i=1}^p n_i)/2$, and this gives the $2H_k$ bound on the competitive ratio.
\end{proof}

\section{Yao's minimax principle and lower bounds}

We will now see a generic method to prove lower bounds against randomized models of computation, and use it to show that any paging algorithm must have a competitive ratio of at least $H_k$. 

Consider a \emph{two-player zero-sum game} between a row player $(R)$ and a column player $(C)$. By a zero-sum game, we mean that every play has a winner and an associated payoff that the loser gives to the winner. Such a game can be characterized by an $m\times n$ matrix $M$ known as the \emph{payoff matrix}. The $m$ rows of $M$ correspond to the actions of $R$, and the $n$ columns of $M$ correspond to the actions of $C$. Then entry $M_{ij}$ corresponds to the payoff that $R$ received from $C$ when $R$ plays $i$ and $C$ plays $j$. For instance, the classical rock-paper-scissors game can be characterized by the following payoff matrix: $-1$ indicates that the column player wins and the row player has to pay the payoff to the column player.
\begin{align*}
\begin{blockarray}{cccc}
	& Rock & Paper & Scissors \\
	\begin{block}{c[ccc]}
		Rock & 0 & -1 & 1 \\
		Paper & 1 & 0 & -1 \\
		Scissors & -1 & 1 & 0 \\
	\end{block}
\end{blockarray}
\end{align*}

What would a good strategy for $R$ look like? There are $3$ possible actions, and for each there is a minimum payoff that he/she receives irrespective of the actions of the player $C$. If $R$ is unaware of the actions of $C$, then the best possible strategy for $R$ is to choose the action that maximizes the minimum payoff that he/she can receive. Similarly for the column player $C$, he/she plays the action that minimizes the maximum payoff that $C$ has to pay $R$ among all his/her actions. The game is said to have a value if 
\begin{align*}
	\max_{i} \min_{j} M_{ij} = \min_{j} \max_{i} M_{ij}.
\end{align*}
In other words, if there exists such an action, then this is the best possible strategy for either of the players if they do not now know the action of the other player. Notice that not all games have such a value - see the example of the rock-paper-scissors game. There $\max_{i} \min_{j} M_{ij} = -1$ and $\min_{j} \max_{i} M_{ij} = 1$.

In particular, it is possible to observe the following statement.
\begin{lemma}
	For every payoff matrix $M$ of a two-player zero-sum game, we have
	\begin{align*}
		\max_{i} \min_{j} M_{ij} \leq \min_{j} \max_{i} M_{ij}.
	\end{align*}
	\label{lem:pure-strat}
\end{lemma}

A strategy where the player choose a fixed action is known as a \emph{pure strategy}. What we have seen is that there need not exist an equilibrium pure strategy for the game. On the other, if we look at \emph{mixed strategies}, then indeed such equilibriums exist. A mixed strategy is a probability distribution over the actions of the corresponding player. The player then chooses an action according to this probability distribution. 

Consider a distribution $\dist{p}$ over the rows of $M$, and a distribution $\dist{q}$ over the columns of $M$. Now, instead of looking at the payoff directly, we will be interested in the expected payoff. This can be easily seen to be
\begin{align*}
	\sum_{i=1}^m \sum_{j=1}^n p_i q_j M_{ij} = \dist{p}^TM\dist{q}.
\end{align*}
Like in the case of pure strategies, the goal of the row player is to choose a distribution $\dist{p}$ such that irrespective of the mixed strategy of $C$, the expected payoff is maximized. But, unlike in the case of pure strategies, there is always an equilibrium for mixed strategies. 
\begin{theorem}[von Neumann Minimax Theorem]
	Let $M$ be a payoff matrix for a two-player zero-sum game. Then,
	\begin{align*}
		\max_{\dist{p}} \min_{\dist{q}} \dist{p}^T M \dist{q} = \min_{\dist{q}} \max_{\dist{p}} \dist{p}^TM\dist{q}.
	\end{align*}
	\label{thm:vn-minimax}
\end{theorem}

Notice that if $\dist{p}$ is fixed, then $\dist{p}^TM \dist{q}$ is a convex sum of the elements of the row vector $\dist{p}^TM$. Consequently, the distribution $\dist{q}$ that minimizes the inner product is the one that puts all the mass on the index with the smallest value. Thus, we have a simply corollary to the minimax theorem that we will use to build the framework for our lower bound proofs.

\begin{corollary}
	Let $M$ be a payoff matrix for a two-player zero-sum game. Then,
	\begin{align*}
		\max_{\dist{p}}\min_j \dist{p}^TM\dist{e}_j = \min_{\dist{q}}\max_i \dist{e}_i^TM \dist{q}.
	\end{align*}
\end{corollary}

Yao's minimax principle is essentially a restatement of the minimax theorem, when a randomized algorithm is viewed as a game. We can think of a game between an algorithm designer and an adversary in the following way: the aim of the designer is to come up with an algorithm that has good performance guarantees on every input, whereas the goal of the adversary is to come up with an input where the algorithm fares poorly. We can think of this as a zero-sum game with a payoff matrix where rows are indexed by the inputs $\mathcal{I}$ and the columns are indexed by algorithms $\mathcal{A}$. The value $M_{ij}$ is the cost of the algorithm $A_j$ on the input $I_i$. For caching algorithms, the cost will be the number of cache misses for the caching algorithm $A_j$ on the input sequence $I_i$.

Observe that we can think of a randomized algorithm as a distribution $\dist{a}$ over the set of all deterministic algorithms on inputs of length $n$, say. Thus, the minimax theorem tells us that 
\begin{align*}
	\max_{\dist{i}} \min_{\dist{A}} \E_{\substack{A\sim \dist{a}\\ I\sim \dist{i}}}[c(A,I)] = \min_{\dist{a}} \max_{\dist{i}} \E_{\substack{A\sim \dist{a}\\ I\sim \dist{i}}}[c(A,I)].
\end{align*}
where $c(A,I)$ is the number of misses for the deterministic algorithm $A$ on the input $I$. Furthermore, from the corollary of the minimax theorem, we can say that
\begin{align*}
	\max_{\dist{i}} \min_A \E_{I\sim \dist{i}} [c(A,I)] = \min_{\dist{a}} \max_I \E_{A\sim \dist{a}} [c(A,I)].
\end{align*}
From this, we can conclude the following about any distribution $\dist{a}$ and $\dist{i}$.
\begin{align*}
	\min_A \E_{I\sim \dist{i}}[c(A,I)] \leq \max_I\E_{A\sim \dist{a}}[c(A,I)].
\end{align*}
Notice that the right-hand side of the inequality is the worst-case expected number of cache misses for a randomized algorithm $\dist{a}$, and the left-hand side is the minimum number of expected misses for any deterministic paging algorithm when the input sequence is distributed according to $i$. Thus, we can conclude the following, which is referred to as Yao's minimax principle.
\begin{theorem}[Yao's minimax principle]
	Suppose there exists a distribution $\dist{i}$ over inputs such that every deterministic algorithm incurs an expected cost (over the input distribution) of $c$. Then, any randomized algorithm will incur an expected cost of at least $c$.
	\label{thm:yao}
\end{theorem}

We will now apply Yao's minimax principle to obtain a lower bound on the expected number of cache misses for any paging algorithm.

\subsection{Lower bound for online paging}

We will prove the following theorem in this subsection. The idea is to design a distribution over inputs such that every deterministic paging algorithm will incur a large number of cache misses in expectation, and conclude using the minimax principle. 

\begin{theorem}
	If an online algorithm for paging (randomized or deterministic) is $c$-competitive, then $c \geq H_k$.
	\label{thm:lb-pagin}
\end{theorem}
\begin{proof}
	We start by defining a distribution over inputs such that any deterministic paging algorithm will incur a large cost. Let $S$ be the set of elements in the cache at the start, and let $i$ be some element that is not present in the cache. Our cache request will be from the set $I = S \cup \{i\}$. The first request will be the element $i$. Thereafter, if the current request was $\sigma_i$, then the next request will be an item chosen uniformly at random from $I \setminus \sigma_i$. 
	
	Once again, we will divide the request sequence into rounds where a round consists of $k$ distinct requests, and end just before the $k+1^{st}$ distinct element is requested. We will argue that any deterministic algorithm will have at least $H_k$ cache misses, whereas the optimal algorithm will have at most one cache miss per round. 
	
	The bound for the optimal algorithm is essentially the same as what we saw before. Since the $k+1^{st}$ distinct element is requested only in the next round and since all the requests are from a set of $k+1$ elements, we can evict the $k+1^{st}$ if there is a cache miss. Now we can be sure that there will be no more cache misses in the current round.
	
	For any deterministic algorithm, the state of the algorithm at a step $i$ of the request sequence is fully characterized by the element not present in the cache at that point. The deterministic algorithm will have a cache miss iff the next element in the sequence is the element that is outside the cache. Since we never request the same element twice in a row, and the requested element is chosen at random from the remaining elements, the probability of a cache miss is $1/k$. To complete, we need to bound the expected length of a round.
	
	To do this, think of the complete graph on the vertex set $I$. At the beginning of a round we are at a vertex $v \in I$, and every request consists of choosing random neighbor and moving to that neighbor. The round ends precisely when we have visited every vertex in the graph. Once we have visited $i$ vertices, the probability that the next vertex will be an unvisited vertex is $(k-i+1)/k$. Thus the expected number of steps before visiting and unvisited vertex is $k/(k-i+1)$. Thus, similar to the bound on the coupon collector problem, we can conclude that the expected length of a round is $kH_k$. This concludes the argument that the expected number of cache misses for any deterministic algorithm is at most $H_k$ per round.
\end{proof}

\section{Bipartite matching revisited}

Let us go back to the online bipartite matching problem. We saw a deterministic
algorithm that was $2$-competitive and a matching lower bound for deterministic
algorithms. The $2$-competitive algorithm was essentially an algorithm that
outputs a maximal matching. We will now give an alternate proof of this fact
using a technique that is going to be useful when we analyze the randomized
algorithm for online bipartite matching.

\subsection{A primal-dual analysis}

The bipartite matching problem for a graph $G(L,R,E)$ can be written as an
integer linear program (ILP) in the following way: Let $x_e$ be a $0$-$1$ variable
corresponding to the edge $e\in E$. We can write the matching problem as a
maximization problem of a function of the variables $x_e$.
\begin{align*}
  & \max  \sum_{e\in E} x_e \\
  & \text{s.t}  \sum_{u\in N(v)} x_{(u,v)} \leq 1, ~\forall v \in V
\end{align*}

While many combinatorial optimization problems can be written as an integer
linear program, solving an ILP is NP-hard in general. One way in which the
theory of linear programming is used to solve combinatorial optimization is to
relax the constraint on the variables to be non-integral and solve the linear
program (LP) instead. In our case, the relaxed LP for matching is the same
as above, with the additional constrains that $x_e \geq 0$. We will call this as
the \emph{primal} LP that we are interested to solve.

A solution to the variables $x_e$ that satisfies all the
constraints is known as \emph{feasible solution}. Notice that every feasible
solution to the ILP written above is indeed a matching. A feasible solution to
the LP is called a \emph{fractional matching}. The problem here is that the
solution of the LP might give non-integral optimal solutions, and we need an
efficient way to \emph{round} these non-integral solutions to integral
solutions. \marginnote{For the matching problem, it is known
  that the optimal solution for the relaxed LP is also obtained via integral
  assignments to $x_e$.}   
Rounding the fractional optimum to an integral feasible solution
might be easy, but it is hard to round it to get an optimum solution, or to a
value that is close to the optimum. In fact, it is possible that there are no
integral optimum solutions. 

The general form of a maximation LP can be written in the following way
\begin{align*}
   \max & \sum_{i=1}^n c_i x_i \\
   s.t & \sum_{j=1}^n a_{ij}x_j \leq b_i, ~ 1\leq j \leq m\\
  & x_i \geq 0, 1\leq i\leq n.
\end{align*}

Now, consider a set of variables $y_1, y_2, \ldots, y_m$ corresponding to each
constraint in the primal LP. The linear function $\sum_{i=1}^m y_i b_i$ is an
upper bound for
$$\sum_{i=1}^m y_i \left(\sum_{j=1}^n a_{ij}x_j \right) =
\sum_{i=1}^n x_i\left( \sum_{j=1}^m y_j a_{ji}\right).$$

Furthermore, if each of the sums $\sum_{j=1}^m y_j a_{ji} \geq c_i$, then
$\sum_{i=1}^m y_ib_i$ is an upper bound on the optimum of the primal
LP. Choosing $y_i$s that make $\sum_{i=1}^m y_ib_i$ smaller gives better bounds
on the optimum of the primal LP (which is a maximization problem in this
case). This leads us to define the \emph{dual} LP as follows.
\begin{align*}
  \min ~&~ \sum_{i=1}^n b_i y_i \\
  s.t ~&~ \sum_{j=1}^m a_{ji}y_j \geq c_i, ~ 1\leq i \leq n\\
  &~ y_j \geq 0, ~ 1\leq j\leq m
\end{align*}

The argument that we presented above is known as \emph{weak duality}.
\begin{lemma}[Weak duality]
  Let ${\cal P}$ be a maximization LP, and let ${\cal D}$ be its dual LP. Then,
  $$\opt({\cal P}) \leq \opt({\cal D}).$$
  \label{lem:weak-dual}
\end{lemma}

The dual LP for the matching problem has one variable $y_v$ for each of the
vertices $v$ in the graph. The dual LP is as follows.
\begin{align*}
  \min ~&~ \sum_{v\in V} y_v \\
  s.t ~&~ y_u + y_v \geq 1, ~\forall (u,v)\in E\\
  &~ y_v \geq 0.
\end{align*}

We will construct a feasible solution to the dual from the solution given by an
algorithm and use the weak duality to argue about the guarantees of the greedy
matching. In general, the primal-dual method involves using the primal and dual
to search for a suitable feasible solution for the dual and construct an optimal
solution for the primal. It will not involve solving the actual
primal or dual LP. We will now reprove the guarantee of the greedy online
matching algorithm using the primal and the dual LPs.

\begin{theorem}
  The greedy online matching algorithm is $2$-competitive.
  \label{thm:greedy-pd}
\end{theorem}
\begin{proof}
  We will define a feasible solution for the dual matching LP from the matching
  created by the algorithm. Let $M$ be the matching produced by the greedy
  algorithm. For every edge $e = (u,v)$, define two variables $q_u$ and $q_v$
  and set both to be $1/2$. Notice that $\sum_{v\in V} q_v = |M|$. Suppose we
  set $y_v = 2q_v$ for every $v\in V$. We want to show that these $y_v$s form a
  feasible solution for the dual; i.e.\ for every every edge $(u,v)$,
  $y_u + y_v \geq 1$.

  This constraint is definitely satisfied when $(u,v)\in M$. For an edge
  $(u,v)\notin M$, one of $y_u$ or $y_v$ is set to $1$. This is because $M$ is
  maximal, and if $(u,v)\notin M$, then some other edge incident on $u$ or $v$
  must be in the matching $M$. This would be mean one of $y_u$ and $y_v$ is set
  to $1$ satisfying the constraint for the edge $(u,v)$.

  Thus we have a feasible solution for the dual with value $\sum_{v\in V} y_v = 2\sum_{v\in v} q_v = 2|M|$. From weak duality, we can conclude that for the maximum matching $M^*$, $|M^*| \leq \sum_{v\in V} y_v = 2\sum_{v\in v} q_v = 2|M|$.
\end{proof}

We will now solve a fractional version of the matching problem, and will use the
primal-dual analysis to prove its competitive ratio. We will then see how to
extend the analysis to obtain the randomized online algorithm for matching.

\subsection{Online fractional matching}

Suppose that we are allowed to partially choose an edge in the matching. In
other words, we want to solve the online version of the LP given in the previous
section. Consider the lower bound graph for the greedy algorithm given to the right.

\begin{marginfigure}
  \centering
  \begin{tikzpicture}
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (l1) at (0,2) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (l2) at (0,0) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (r1) at (2,2) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (r2) at (2,0) {};
    \node[left =0cm of l1] {$\ell_1$}; \node[left =0cm of l2] {$\ell_2$};
    \node[right =0cm of r1] {$r_1$}; \node[right =0cm of r2] {$r_2$};
    \draw[thick,-] (l1) to node[midway,above] {$\tfrac{1}{2}$} (r1);
    \draw[thick,-] (l2) to node[pos=0.2,above] {$\tfrac{1}{2}$} (r1);
    \draw[thick,-] (l1) to node[pos=0.8,above] {$\tfrac{1}{2}$}  (r2);
  \end{tikzpicture}
  \caption{Instance of fractional matching with fractional values to the edge
    variables in the primal LP for the lower bound graph.}
  \label{fig:lbgraph-flp}
\end{marginfigure}
Suppose that we have $r_1$ coming first and revealing the edges $(\ell_1,r_1)$
and $(\ell_2, r_2)$. We could set the variables corresponding to both the edges
to $1/2$, and the setting the edge $(\ell_1, r_2)$ to $1/2$. This gives a
feasible solution of value $3/2$ to the primal LP. The optimum is still $2$, but
we have a $3/4$-approximation. It turns out that we can do better than the
greedy if we are searching for fractional matchings using a deterministic
algorithm. This algorithm is called the \emph{waterlevel algorithm} and is a
$1-1/e$ approximation of the maximum matching. The problem of rounding the
fractional solution to an integral solution still remains, and our lower bound
proves that we cannot do it deterministically. We will use the ideas in the
analysis of the fractional matching algorithm to analyze the randomized
algorithm for online bipartite matching.

Think of the vertices in $L$ of $G$ to be containers of unit capacity, and the
vertices in $R$ to be reservoirs that supply one unit of water. The edges are
pipelines that connect the reservoir to the containers. When a new vertex
$v\in R$ arrives with the edges to vertices in $N(v)$, the water starts flowing
from the $v$ to the containers in $N(v)$ which are filled least at an equal
rate. This continues until containers are full or the reservoir runs out of
water. Let's look at an example on the right.
\begin{marginfigure}
  \centering
  \begin{tikzpicture}
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (l1) at (0,2) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (l2) at (0,1) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (l3) at (0,0) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (l4) at (0,-1) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (r1) at (2,2) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (r2) at (2,1) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (r3) at (2,0) {};
    \node[circle,draw,thick,minimum size=5pt,inner sep=0pt] (r4) at (2,-1) {};
    \node[left =0cm of l1] {$\ell_1$}; \node[left =0cm of l2] {$\ell_2$};
    \node[left=0cm of l3] {$\ell_3$}; \node[left=0cm of l4] {$\ell_4$};
    \node[right =0cm of r1] {$r_1$}; \node[right =0cm of r2] {$r_2$};
    \node[right =0cm of r3] {$r_3$}; \node[right =0cm of r4] {$r_4$}; 
    \draw[thick,-] (l1) to node[pos=0.5,above] {$\tfrac{1}{3}$} (r1);
    \draw[thick,-] (l2) to node[pos=0.1,above] {$\tfrac{1}{3}$} (r1);
    \draw[thick,-] (l1) to node[pos=0.9,above] {$\tfrac{1}{3}$}  (r2);
    \draw[thick,-] (r1) to node[pos=0.9,above] {$\tfrac{1}{3}$}  (l3);
    \draw[thick,-] (r2) to node[pos=0.2,above] {$\tfrac{2}{3}$}  (l4);
    \draw[thick,-] (r3) to node[pos=0.1,above] {$\tfrac{1}{3}$}  (l4);
    \draw[thick,-] (r4) to node[pos=0.1,above] {$\tfrac{2}{3}$}  (l3);
    \draw[thick,-] (r4) to node[pos=0.5,below] {$0$} (l4);
  \end{tikzpicture}
  \caption{An example run of the waterlevel algorithm. The edge weights are the
    final values to the variables in the primal LP.}
  \label{fig:waterlevel-algo}
\end{marginfigure}
Suppose that the vertices $r_1$, $r_2$, $r_3$, and $r_4$ arrive in that
order. When $r_1$ arrives it divides its water to $\ell_1$, $\ell_2$, and
$\ell_3$ and the containers are $1/3$ full. Now, when $r_2$ arrives, it starts
filling $\ell_3$ until both $\ell_1$ and $\ell_3$ are $1/3$ full. After this
$r_2$ distributes the remaining $2/3$ units of water it has equally between
$\ell_1$ and $\ell_3$. This stops when $r_2$ is empty, at which point $\ell_1$
and $\ell_4$ are $2/3$ full, and $\ell_2$ and $\ell_3$ are $1/3$ full. When
$r_3$ arrives, $\ell_4$ is already $2/3$-full, and hence $r_3$ can empty only
$1/3$ of its contents before $\ell_4$ is filled to capacity. Finally when $r_4$
arrives, it empties $2/3$ of its contents to $\ell_3$ and stops since both
$\ell_3$ and $\ell_4$ are filled to capacity. The fractional matching weights
are shows in the figure.

If we try to analyze using the primal-dual method, we need to obtain a feasible
solution for the dual LP from this algorithm. One way to do this would be
imitate the way we proceeded with the greedy algorithm. There, when an edge
$e = (u,v)$ was selected (which was equivalent to setting the corresponding
variable to $1$), we set $q_u$ and $q_v$ to $1/2$, and then the feasible
solution was obtained by setting $y_v = 2q_v$. If we try to imitate this by
$q_v$ to be the sum of half of the weights for each of the edges, then
$\sum_{v\in V} q_v$ is the value of the fractional matching. If we can show that
$y_v = kq_v$ for some $k < 2$, is a feasible dual solution, then this will give
a better competitive ratio. Unfortunately, in the worst case, $k$ will have to
be $2$. To see this, consider the input in Figure~\ref{fig:waterlevel-algo}, but
now there is a new vertex $r_5$ that appears at the end and is connected only to
$\ell_4$. There is no outflow from this reservoir since the container is up to
full capacity. The value of $q_{\ell_4} = 1/2$, and $q_{r_5} = 0$. Thus, the
only way to obtain a feasible solution for the dual by this method would be to
have $k=2$ which does not give a better bound than the greedy.

Note that this need not be an issue with our algorithm, but an inability on our
part to construct a suitable feasible solution to the dual LP. Let's try to
obtain $q_v$s in a more sophisticated way. Consider a splitting function $g$
that decides the value of $q_u$ and $q_v$ for any edge $(u,v)$ (where $u\in L$)
based on how much water is present in the container $u$, rather than split it
equitably. Let's assume that we want a non-decreasing function $g$. If the
current amount is $t_u$, then for the next $dy$ amount of flow, the value of
$q_u$ is increased by $g(t_u) dy$. Similarly, we will increase the value of
$q_w$ by $(1 - g(t_u))dy$. Thus, if the final quantity of water in the container
$u$ at the end of the algorithm is $t_u$, the value of $q_v$ is given by the
equation
\begin{align*}
  q_u = \int_0^{t_u} g(y) dy.
\end{align*}

The goal is to find a suitable function $g$ so that we can construct an
appropriate dual feasible solution as before. For an edge $(u,v)$ where $u\in L$
and $v\in R$, suppose that $u$ is full. Then we can write
\begin{align*}
  q_u + q_v \geq q_u = \int_0^{1} g(y) dy
\end{align*}
We have seen that this can happen where the reservoir $v$ cannot send water to any container since they are all full.

Notice that in the waterlevel algorithm, a vertex $v$ sends water only if it
contains some water, and there is at least one neighbor that is not filled to
capacity. If water level in $u$ at the end of the algorithm was $t_u < 1$, then
whenever $v$ was sending water to any vertex $w$, it must have been the case
case that the water level in $w$ is at most $t_u$. Furthermore, if $t_u < 1$,
then the reservoir $v$ must have been completely empty. Hence, we can obtain an
lower bound for $q_v$ as follows.
\begin{align*}
  q_v \geq \int_{0}^1 (1 - g(t_u))dy \geq 1 - g(t_u).
\end{align*}

Thus, we can obtain the following lower bound for $q_u + q_v$:
\begin{align*}
  q_u + q_v \geq (1 - g(t_u)) + \int_0^{t_u} g(y) dy.
\end{align*}

At this point, it is not clear whether such a function exists. Notice that the
lower bound written above depends on the value of $t_u$ of the water level in
the container $u$. Let's see if we can find a lower bound that is independent of
this value. In other words, we want $(1-g(t_u)) + \int_0^{t_u} g(y)dy$ when
considered as a function of $t_u$ is a constant. Thus, we get the following
equation $ g(t_u) - g'(t_u) = 0$, giving us $g(y) = ce^y$. Now, if we want the
two lower bounds for $q_u+q_v$ to be the same, we have
\begin{align*}
  \int_0^1 ce^y dy = (1 - ce^{t_u}) + \int_0^{t_u} ce^y dy
\end{align*}

Solving this gives $c = 1/e$, and thus $g(y) = e^{y-1}$. Now we can see that for
any edge $e = (u,v)$, we have
\begin{align*}
  q_u + q_v \geq \int_0^1 e^{y-1}dy = 1 - 1/e
\end{align*}

We will set $y_u = \frac{e}{e-1} q_u$ for every vertex $u\in V$, and thus for
every edge we have $y_u + y_v = \frac{e}{e-1}(q_u + q_v) \geq 1$. Thus this
forms a feasible solution for the dual. Since $\sum_{u\in V} q_u$ is equal to
the size of the fractional matching $|M|$, we have
$\opt \leq \sum_{u\in V} y_u = \frac{e}{e-1} |M|$.

\subsection{Online bipartite matching - the final piece}

%\begin{algorithm}[H]
%  
%  \label{alg:waterlevel}
%\end{algorithm}


We will now see a randomized online algorithm for bipartite matching that
achieves a competitive ratio of $1 - 1/e$. It can also be shown using the
minimax principle that this is the best bound achievable by any online
algorithm. This algorithm, \ranking, was first described by Karp, Vazirani and
Vazirani.

\begin{algorithm}[h]
  \KwIn{$G(L,R,E)$, where $L$ is known and $R$ is revealed online}
  
  Choose a permutation $\pi$ uniformly at random and order vertices of $L$
  according to $\pi$
  
  $M \gets \emptyset$
  
  \ForEach{$v\in R$ and its neighbors $N(v)$ revealed online}{ Find the
    first vertex $u \in N(v)$ (according to $\pi$) that is unmatched
  	
  	$M \gets M \cup \{u,v\}$
  }
  \label{alg:ranking}
  \caption{\ranking}
\end{algorithm}

We will state this algorithm slightly differently. Instead of a random
permutation on $L$, we will assume that for each $u\in L$, we choose a random
number $\ell$ uniformly at random in $[0,1]$. Now, whenever a vertex $v\in R$
arrives, $r$ is matched to an unmatched vertex in $N(v)$ with the smallest
$\ell$ value. It is not hard to see that choosing random numbers in $[0,1]$ for
each vertex in $L$ is equivalent to choosing a random ordering of $L$.

In line with our waterlevel analogy, we will assume that $\ell_u$ is the
capacity of the container corresponding to the vertex $u$, and matching $v$ to
$u$ is sending $\ell_u$ amounts of water to $u$ and stopping. Analogous to the
fractional matching case, we will divide this flow $\ell_u$ to the vertices as
follows: we will set $q_u = e^{\ell_u - 1}$ and $q_v = 1 -
e^{\ell_u-1}$. Clearly, by definition, we have
$\sum_{u\in L} q_u + \sum_{v\in R} q_v = |M|$, the size of the matching output
by the algorithm. Note that $q_u$ and $q_v$ are random variables, and hence the
size of the matching output by the algorithm is also a random variable. In
contrast to what we did for the waterlevel algorithm, here we will actually
construct a dual solution (that may be infeasible) where the dual variables are
random variables. We will show that the expected value of these random variables
are feasible for the dual.

To bound the expectation of $q_u$ and $q_v$, we need the following observations
regarding bounds on the values that they can take. Let $(u,v)\in E$ and suppose
we fix the value of $\ell_{u'}$ for all $u'\in L \setminus \{u\}$. Consider the
case of running the algorithm on the graph $G \setminus \{u\}$. Let $\ell^*$ be the
value of vertex $u^*$ to which $v$ is mapped in this case (assume that
$\ell^* = 1$ if $v$ is not mapped). Then the following statements hold.

\begin{claim}
  If $\ell_u < \ell^*$, then $u$ is matched by some vertex when the
  algorithm runs on $G$.
\end{claim}
\begin{proof}
  We will actually show that if $u$ is unmatched until $v$ arrives, then $u$
  will get mapped to $v$. To see this, notice that if $u$ is unmatched until $v$
  arrives, then the behaviour of the algorithm on $G$ and $G\setminus \{u\}$ is
  identical up till this point. So, when $v$ arrives and $\ell^* > \ell_u$,
  surely $v$ will choose $u$ to get mapped to.
\end{proof}

\begin{claim}
  $q_v > 1 - e^{\ell^* - 1}$, for all choices of $\ell_u$.
\end{claim}
\begin{proof}
  Let us run the algorithm on $G$ and $G\setminus \{u\}$. The unmatched vertices
  on $G$ is a superset of the unmatched vertices when the algorithm is run on
  $G\setminus \{u\}$. This can be seen inductively. So, when $v$ arrives, it's
  choice in $G$ will be with $u'$ such that $\ell_{u'} \leq
  \ell_{u^*}$. Consequently, $q_v \geq 1 - e^{\ell^* - 1}$.
\end{proof}

Thus the expectation of $q_v$ conditioned on all fixing all the $\ell_{u'}$ for
$u' \in L \setminus \{u\}$ is $\E[q_v] \geq 1 - e^{\ell^* - 1}$. Similarly, the
conditional expectation of $q_u$ can be computed as follows using the first claim.
\begin{align*}
  \E[q_u] \geq \int_{0}^{\ell^*} e^{x-1} dx = e^{\ell^*-1} - \frac{1}{e}.
\end{align*}

Thus, we have $\E[q_u + q_v] \geq 1 - \tfrac{1}{e}$ for every edge $(u,v)\in
E$. Define $y_u = \tfrac{e}{e-1} q_u$ for all the vertices in the graph. Thus,
for every edge $(u,v)\in E$, $\E[y_u] + \E[y_v] \geq 1$. Hence, the expectations
are feasible for the dual. Thus, we can write
\begin{align*}
  \opt \leq \E\left[\sum_{u\in L} y_u + \sum_{v\in R} y_v \right] = \frac{e}{e-1} \E\left[\sum_{u\in L} q_u + \sum_{u\in R} q_v \right] = \frac{e}{e-1}\E[|M|].
\end{align*}


\subsection{An economics-based proof of the \ranking algorithm}

In this section, we will see an analysis of the \ranking algorithm that will
look very similar to the one before, but stated in a slightly different
language. While this analysis can be read independently of the analysis above,
some of the choices made can be better appreciated if the primal-dual analysis
is read.  Just like before, we will show that the expected size of the matching
computed by \ranking (where the expectation is over the random permuation in
Step~$1$) is at least $(1-1/e)\cdot \opt$, where $\opt$ is the size of the
maximum matching.

To that end, we will view this algorithm as a market process between buyers and
items. Let $L$ be a set of items such that each item $i$ has a price $p_i$. Now,
$R$ consists of a set of buyers where each buyer $j$ has a valuation $v_j(i)$
for each item item $i \in N(j)$. The utility of an item $i$ for a buyer $j$,
denoted by $u_j(i) = v_j(i) - p(i)$. The buyers arrive in an online fashion, and
buyer $i$ purchases the item with the highest utility in $N(i)$ that has not yet
been sold. We will assume that the prices are set in a randomly, by first
sampling a number $w$ uniformly at random from the interval $[0,1]$ and setting
the price $p_i$ to be $e^{w-1}$. The valuation $v_j(i)$ is set to $1$ for each
buyer $j$ and item $i$.

Since we are sampling from a distribution with no point mass, there are no two prices that are same, and it induces an ordering on the items in $L$. Thus, the market process corresponds to running the \ranking algorithm with the permutation corresponding to what is given by the prices. In other words, if $M$ is the matching given by the \ranking algorithm and $M'$ the matching given by the market process, we have
\begin{align*}
	\E_\pi [M] = \E_w[M'].
\end{align*}

To analyze this algorithm, let us first write the size of the matching given by the market process using the utility obtained by the buyers and the revenue generated. For a price list $\dist{w}$ generated as above, let us define the utility for the user $i$ to be $1 - p_j$ if the user has bought item $j$ and $0$ otherwise. For an item $j$, we will define the revenue to be $r_j$ is the item was purchased during the market process. Observe that we can write the size of the matching $M'$ as follows:
\begin{align*}
	|M'| = \sum_{i\in L} r_i + \sum_{j\in R} u_j
\end{align*}
Let $M^*$ be a maximum matching, we can then write
\begin{align*}
	\E[|M'|] &= \E\left[\sum_{i\in L} r_i + \sum_{j\in R} u_j \right] \geq \E\left[ \sum_{(i,j)\in M^*} (r_i + u_j) \right]\\
	&= \sum_{(i,j)\in M^*} \E[r_i + u_j]
\end{align*}

To complete the proof, we need to prove the following claim.
\begin{claim}
	Let $(i,j)$ be any edge in the graph $G$. Then $\E[r_i + u_j] \geq 1 - 1/e$.
\end{claim}
\begin{proof}
	Consider the same market process with the same sequence except the item $i$. Let $M'_i$ be the matching generated by the market process in this case. Let $p^* = e^{w^* - 1}$ be the price of the item purchased by the buyer $j$ in $M'_j$. If $j$ does not purchase any item, then set $p^* = 1$. 
	
	Notice that if $p_i < p^*$, then the item $i$ is purchased by some buyer in $M'$. This is because if it was not purchased by the time buyer $j$ arrives, then the utility $u_j(i) = 1 - p_i > 1 - p^*$ and hence $j$ will purchase $i$. Furthermore, the utility of $j$ in $M'$, $u_j > 1 - p^*$ since adding a new item cannot reduce the utility. Therefore, $\E[u_j] > 1 - p^*$. 
	
	Now $\E[r_i] = \E[p_i I_[\text{$i$ is purchased}]] \geq \E[p_i I[p_i < p^*]]$. The final inequality follows from the first observation in the last paragraph. Thus, we can write
	\begin{align*}
		\E[r_i] \geq \int_{0}^{w^*} e^{w-1} dw = p^* - \frac{1}{e}.
	\end{align*}
    Thus, we have $\E[r_i + u_j] \geq 1 - 1/e$ and this concludes the proof.
\end{proof}


\section{The weighted majority algorithm}

Consider a decision making problem where you have to make a yes/no decision everyday, and if you make the wrong decision you have to pay a thousand rupees to an adversary. If you make the correct decision, then you do not have to pay anything. Now, the catch is that the adversary can reveal to you the correct answer only after you say your decision. Clearly, this game is loaded in favor of your adversary for he/she can force you to pay up at every step.

Now consider the case that there are $n$ experts $e_1, e_2, \ldots, e_n$ whom you can listen to while making a decision. Instead of measuring your performance in the worst-case scenario, you would like to measure it in terms of the performance of the best experts among the $n$. In other words, we are interested in the quantity
\begin{align*}
	\min_{i\in [n]} \{ m^{(i)}_T \} - m_T,
\end{align*}
where $m^{(i)}_T$ is the number of times that the $i^{th}$ expert made a wrong decision and $m_T$ is the number of times you made the wrong decision in $T$ steps. We would like to make this as small as possible. Let us start with a simple warm-up that we will generalize.

\subsection{Omniscient expert}

Assume that among the $i$ experts, there exists an omniscient expert who can make the correct decision every time. We will see we can find the identity of such an expert in $\log n$ steps where we made an incorrect decision, and hence $\min_{i\in [n]} \{ m^{(i)}_T \} - m_T \leq \log n$. The idea is that at every step we take the majority decision of the remaining experts, and once the correct decision is revealed we throw away all the experts who gave incorrect answers at that stage. The omniscient expert is never thrown away, and furthermore if we make an incorrect decision, this means that at least half of the experts in that stage can be identified as bad experts and thrown away.

\subsection{General case}

In the general case, there need not be any omniscient expert. We also cannot make any assumptions on how the experts are correlated. For instance, maybe there is a clique of $k$ experts who always give the same answer. The idea of the weighted majority algorithm is fairly simple. Initially, we are unaware of which of the experts really know what they are talking about. So, we trust each of their decisions equally well. But then once we see how they fare, we factor that in and re-weight our trust in the experts. This is described in Algorithm~\ref{alg:wgtd-maj}.

\begin{algorithm}%[h]
	Set $w_i^{(1)} \gets 1$ for every $i \in [n]$
	
	\For{$t = 1$ to $T$}{
		Let $S_0$ be the experts who say no, and let $S_1$ be the expert who says yes.
		
		\leIf{$\sum_{i\in S_0} w_i^{(t)} \geq \sum_{i\in S_1} w_i^{(t)}$}{
			decide no
		}{
			decide yes
		}
		
        \ForEach{wrong expert $i$}{set $w_i^{(t+1)} \gets (1-\epsilon)w_i^{(t)}$}
	}
	\caption{\textsc{Weighted Majority}}
	\label{alg:wgtd-maj}
\end{algorithm}

In the first step we take the majority vote, but after that we scale down the weight of wrong experts. The factor $\epsilon$ in the algorithm is a weighting factor that decides by how much we should rescale a wrong experts advice. We can show that this simple algorithm already achieves almost the best that we can achieve by deterministic algorithms.

\begin{theorem}
	Let $m_T$ be the number of mistakes made by the weighted majority algorithm after in $T$ steps, and let $m^{(i)}_T$ be the number of mistakes made by expert $i$ in $T$ steps. Then, for every $i \in [n]$ we have
	\begin{align*}
		m_T \leq 2(1+\epsilon)m^{(i)}_T + \frac{\ln n}{\epsilon}.
	\end{align*}
	\label{thm:wgtd-maj}
\end{theorem}
\begin{proof}
	The proof is similar in spirit to the case of the omniscient expert. Let us define a potential function $\Phi(t) = \sum_{i=1}^n w_i^{(t)}$. We will show that at each time step that we make an erroneous decision the potential function reduces by a constant factor.
	
	Firstly, notice that for any expert $i$, we have $w_i^{(t)} = (1-\epsilon)^{m_T^{(i)}}$. If at time step $t$, the algorithm makes a wrong decision (say the algorithm said no w.lo.g), then we can write
	\begin{align*}
		\Phi(t+1) &= \sum_{i\in S_0} w_i^{(t+1)} + \sum_{i\in S_1} w_i^{(t+1)}\\
		&= (1-\epsilon)\sum_{i\in S_0} w_i^{(t)} + \sum_{i\in S_1} w_i^{(t)}\\
		&\leq \left( 1 - \frac{\epsilon}{2}\right)\Phi(t).
	\end{align*}

	Thus, after $T$ steps, for every $i\in [n]$ we have
	\begin{align*}
          (1-\epsilon)^{m_{T}^{(i)}} \leq \Phi(T) \leq \left(1 - \frac{\epsilon}{2} \right)^{m_T}n
	\end{align*}
	Now we can use the bound that $\ln(1-x) \geq -x - x^2/2$, to write the
        following.
        \begin{align*}
          m_T^{(i)}\ln (1 - \epsilon) &\leq \ln n - \frac{\epsilon}{2}m_T\\
          m_T^{(i)} \left( -\epsilon - \frac{\epsilon^2}{2} \right) &\leq \ln n - \frac{\epsilon}{2} m_T
        \end{align*}
        The theorem follows by rearranging the terms.
      \end{proof}

\subsection{A simple lower bound}

Notice that if $m_T^{(i)} \gg \frac{\ln n}{\epsilon}$, then
$m_T \leq 2(1+\epsilon) m_T^{(i)}$. If we look at any deterministic online
decision making process, then the factor of $2$ is unavoidable.

To see this consider two experts $e_0$ and $e_1$ where $e_i$ always answers
$i$. The decisions of any deterministic algorithm can be computed by an
adversary, and the adversary can always give the opposite decision as the
correct decision. Hence, the loss incurred by the algorithm over $T$ rounds is
$T$. On the other hand, irrespective of the decisions of the adversary, the best
expert will incur at most $T/2$ losses throughout the entire run. We will look
at a more general version of the weighted majority algorithm, using
randomization that gives a better guarantee.
      

\section{The Multiplicative Weights Update (MWU) method}

In this part we will look at a generic meta-algorithm known as the
multiplicative weights update (MWU) method that generalizes the weighted
majority algorithm that we saw earlier. The analysis is elementary, like in the
case of the weighted majority algorithm, but very many different algorithms can
be phrased in the terminology of MWU.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "notes"
%%% End:
